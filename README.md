# COMP442Project

### How to replicate (after installs)
- First we need to finetune/train mbart50 model. I used the methods mentions in (https://github.com/alisafaya/mukayese) to clone transformers (https://github.com/huggingface/transformers) and train mbart50 model for 5 epochs.
- Then we need to evaluate the model on wmt16 en-tr dataset. To do this I wrote the JSONToInput function in convertDatasets.py and processTR_EN(or EN_TR for other direction).py. converting json file to a list of sentences and giving them to the model one batch at a time gives us the translations generated by mbart50.
- Then we need to reconstruct our dataset (which we can do with outputToJSON function I wrote in convertDatasets.py) and we can train our models with standart training dataset as well as the modified dataset.
- Then we can test our models using myTest.py file to obtain BLEU scores (with 4 different weight configurations)
### Descriptions of folders and files
- ensemble & vanilla folders: There are two folders in each of them for EN->TR and TR->EN. All 4 of these folders are modified clones of this github page (https://github.com/bkoch4142/attention-is-all-you-need-paper) which gives an implementation of transformer model as well as training code for DE->EN NMT. My main addition is the test code i used which is called myTest.py, and I made some necessary additions to dataset.py file as well. I made some changes to train.py to get wandb to work and to config.py to adjust the configurations (all 4 mentioned files are under src folder).
- mbart50_outputs: These are the outputs I got from the mbart50 model after finetuning it for 5 epochs on the wmt-16 TR-EN dataset. These are the sequence outputs of the model for the training split of this dataset.
- Results: contains the outputs I received in this project
- PreprocessCode: The preprocess related python codes I wrote
